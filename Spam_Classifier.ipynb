{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75e8f98feb36689",
   "metadata": {},
   "source": [
    "# Spam/Ham SMS Message Classifier\n",
    "\n",
    "**A machine learning project to automatically detect spam messages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8739873d1b4a287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T03:17:38.053946Z",
     "start_time": "2025-08-28T03:17:37.016357Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca266f333ed131f",
   "metadata": {},
   "source": [
    "### Project Constants\n",
    "\n",
    "**`RANDOM_SEED` ensures that our train-test split is reproducible, meaning it will be the same every time we run the code.**\n",
    "\n",
    "**`TEST_SIZE` defines the proportion of the dataset that will be used for testing (in this case, 20%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd5b176a543c347",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\el1syum\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(message):\n",
    "    message = re.sub('[^a-zA-Z]', ' ', message).lower().strip().split()\n",
    "    message = [word for word in message if word not in stop_words]\n",
    "    return ' '.join(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101255181e92e34",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "\n",
    "**This step prepares the text for analysis. First, we download a list of common English stopwords (e.g., 'a', 'the', 'is') from NLTK. These words are usually uninformative and can be removed.**\n",
    "\n",
    "**The `preprocess_text` function then performs the following actions on each message:**\n",
    "**1. Removes all punctuation and numbers.**\n",
    "**2. Converts all characters to lowercase.**\n",
    "**3. Splits the text into individual words (tokens).**\n",
    "**4. Removes all stopwords from the list of tokens.**\n",
    "**5. Joins the cleaned words back into a single string.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338efa89f388feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spam.csv', encoding='latin1')\n",
    "\n",
    "data_renamed = data[['v1', 'v2']].rename(columns={\"v1\": \"label\", \"v2\": \"message\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca1f1cf2d4b31a0",
   "metadata": {},
   "source": [
    "### Data Loading and Cleaning\n",
    "\n",
    "**We load the dataset using pandas. The `encoding='latin1'` parameter is used to prevent potential encoding errors with this specific file.**\n",
    "\n",
    "**The initial columns are named 'v1' and 'v2'. We rename them to `label` and `message` for better readability.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f8a6b4caec81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_renamed['message_len'] = data_renamed['message'].str.len()\n",
    "\n",
    "avg = data_renamed.groupby(['label'])['message_len'].mean()\n",
    "print(f\"AVG:\\n{avg}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349647fe8abd53fc",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Let's investigate if there is a difference in length between spam and ham messages. We create a new column, `message_len`, to store the length of each message.**\n",
    "\n",
    "**By grouping the data by `label` and calculating the mean, we can see the average message length for each class.**\n",
    "\n",
    "**As the output shows, spam messages are, on average, significantly longer than ham messages. This is a useful insight.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991b89d3de49031",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_renamed['cleaned_message'] = data_renamed['message'].apply(preprocess_text)\n",
    "print(f\"\\nDATA:\\n{data_renamed[['message', 'cleaned_message']].head()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b37df2bd428736",
   "metadata": {},
   "source": [
    "**Now, we apply our `preprocess_text` function to every message in the dataset to create a new `cleaned_message` column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6306d218ba5e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_renamed['cleaned_message']\n",
    "y = data_renamed['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41b8b413128d42",
   "metadata": {},
   "source": [
    "### Feature and Target Split\n",
    "\n",
    "**We define our features (`X`) as the cleaned messages and our target (`y`) as the labels. Then, we split the data into training and testing sets using `train_test_split`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e62220b28130ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca596985368466a",
   "metadata": {},
   "source": [
    "### Text Vectorization (TF-IDF)\n",
    "\n",
    "**Machine learning models cannot work with raw text. We need to convert the text data into numerical vectors. We use `TfidfVectorizer` for this, which calculates the \"Term Frequency-Inverse Document Frequency\" for each word. This method reflects how important a word is to a document in a collection.**\n",
    "\n",
    "**Crucially, we `fit_transform` on the training data and only `transform` the test data to prevent data leakage.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cac51b92373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d1bb05ae6aeefb",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "**We choose the `Multinomial Naive Bayes` classifier, a simple but effective algorithm for text classification.**\n",
    "\n",
    "**The `model.fit()` command trains the model. During this process, the model learns the probability of each word appearing in spam versus ham messages based on the training data (`X_train_tfidf` and `y_train`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2f999c2330513",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cef86e07c62542",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "\n",
    "**Now that the model is trained, we use it to make predictions on the test data (`X_test_tfidf`), which it has never seen before. The results are stored in `y_pred`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace051749a9c65df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First way to check model accuracy (handmade)\n",
    "correct = sum([list(y_test)[i] == y_pred[i] for i in range(len(y_pred))])\n",
    "accuracy_1 = correct / len(y_pred)\n",
    "print(f\"\\nAccuracy 1: {accuracy_1}\\n\")\n",
    "\n",
    "# Second way to check accuracy (handmade, better, with numpy)\n",
    "matches = (y_test == y_pred)\n",
    "accuracy_2 = np.sum(matches) / len(y_test)\n",
    "print(f\"\\nAccuracy 2: {accuracy_2}\\n\")\n",
    "\n",
    "# Third way to check accuracy (auto)\n",
    "accuracy_3 = model.score(X_test_tfidf, y_test)\n",
    "print(f\"\\nAccuracy 3: {accuracy_3}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a8ad27436a84a",
   "metadata": {},
   "source": [
    "**As we can see, all three methods yield the exact same accuracy score. This confirms our understanding of how the metric is calculated.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ac3ab087164cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th way to check accuracy (and other info)\n",
    "class_rep = classification_report(y_test, y_pred)\n",
    "print(f\"\\nClassification Report:\\n{class_rep}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2837be745a557d04",
   "metadata": {},
   "source": [
    "**While accuracy is a good starting point, it can be misleading, especially with imbalanced datasets. For a more detailed view of the model's performance, we use a `classification_report`.**\n",
    "\n",
    "**It provides key metrics like `precision`, `recall`, and `f1-score` for each class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5764fb4d061073",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_max = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\\n{conf_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e439eabf1fc9f06",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "**The confusion matrix gives us a clear breakdown of the model's predictions versus the actual labels.**\n",
    "\n",
    "**From this matrix, we can see:**\n",
    "**- **False Positives (FP): 0**. The model never incorrectly classified a 'ham' message as 'spam'. This is an excellent result.**\n",
    "**- **False Negatives (FN): 36**. The model missed 36 spam messages, classifying them as 'ham'.**\n",
    "\n",
    "**This explains the `recall` score of 0.76 for the 'spam' class: the model successfully identified 76% of all actual spam messages. While the overall accuracy is high, there is still room for improvement in catching more spam.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
